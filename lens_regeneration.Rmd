---
title: 'STA463 Course Extension: Lens Regeneration'
author: "Davyd Sadovskyy"
date: "4/29/2023"
output: html_document
---

H~2~O

``` {r}
library(tidyr)
library(zoo)

data <- read.csv("lens_regeneration_data.csv", header=TRUE)

# Data Cleaning
data$X <- NULL # Remove random column that was in data
data <- data[data$Rep != "Rep",] # Remove the 11 rows of headers
row.names(data) <- NULL # reset the row indexes - they got messed up when we removed rows
data[data == ""] <- NA # replace all empty string values with NA

data$Rep <- na.locf(data$Rep) # Fill in empty values in Rep column with values above
# Fill in NA values with most recent prior NA value
data[,c("Rep","Slide","Section")] <- na.locf(data[,c("Rep","Slide","Section")]) 
larvae <- rep("Larvae", 162)
juvenile <- rep("Juvenile", 162)
adult <- rep("Adult", 162)
day1 <- rep("1", 486)
day4 <- rep("4", 486)
day10 <- rep("10", 486)
day15 <- rep("15", 486)
data["Age"] <- rep(c(larvae, juvenile, adult), 4) # Add the life stage variable
data["Day"] <- c(day1, day4, day10, day15) # Add the day variable
# Change the type of the Age and Day columns to factor and set the baseline levels
data$Age <- factor(data$Age)
data$Day <- factor(data$Day)
data$Age <- relevel(data$Age, ref="Larvae")
data$Day <- relevel(data$Day, ref="1")
# create dummy variables for the Age factor. The result is a new matrix
life_stage_dummy <- model.matrix(~Age, data=data)[,-1] # [,-1] drops the intercept column 
day_dummy <- model.matrix(~Day, data=data)[,-1]
# convert matrixes to dataframes
life_stage_dummy_df <- as.data.frame(life_stage_dummy)
day_dummy_df <- as.data.frame(day_dummy) 
# Combine the dummy variables into one predictor variable data frame
combined_dummies <- cbind(life_stage_dummy_df, day_dummy_df)
# Rename the age indicator variables
colnames(combined_dummies)[1:2] <- c("Adult", "Juvenile")
# Remove the old factor variables that we don't need anymore
#data <- data[,!names(data) %in% c("Age", "Day")]
# Switch column locations
data <- data[,c(1:4,7,8,5,6)]

# Now combine dummy variables with original data
data2 <- cbind(data, combined_dummies)
# Make columns that the model will be built on numeric
data2[,7:13] <- lapply(data2[,7:13], as.numeric)
# The dataset has incorrect totals so I have to redo everything...
# create new column of the EdU count for each section
edu_totals <- c()
dapi_totals <- c()
for (i in seq(3, length(data2$EdU), by=3)) {
  new_edu_total <- sum(data2$EdU[(i-2):(i-1)])
  new_dapi_total <- sum(data2$DAPI[(i-2):(i-1)])
  edu_totals <- c(edu_totals, new_edu_total)
  dapi_totals <- c(dapi_totals, new_dapi_total)
}
# We are only interested in total cell counts so we select every third row here
data2 <- data2[seq(1, nrow(data2),3),]
# Replace the EdU and DAPI columns with those we calculated
data2$EdU <- edu_totals
data2$DAPI <- dapi_totals
# Drop the irrelevant Area column
data2$Area <- NULL
row.names(data2) <- NULL # reset the row indexes - we selected every third observation
# Make the Day column numeric
data2$Day <- as.integer(as.character(data2$Day))

# Make the Hoechst cell column
data2$Hoechst <- data2$DAPI - data2$EdU
# Drop the NA observation
data2 <- data2[complete.cases(data2), ]
# Make extra column of centered Day predictor
day_mean <- mean(data2$Day)
data2$day_centered <- data2$Day - day_mean
# Add a modified response
data2$log_edu_hoechst <- log(data2$EdU/data2$Hoechst)

# Make a dataframe where log(edu/hoechst) -infinity observations are ommited
data3 <- subset(data2, log_edu_hoechst != -Inf)
```


``` {r}
# some EDA

missing_rows_indexes <- which(apply(is.na(data2), 1, any))
data2[missing_rows_indexes,]

install.packages("ggplot2")
install.packages("gridExtra")
library(ggplot2)
library(gridExtra)
library(cowplot)
ggplot2::ggdraw()
install.packages("vioplot")
library(vioplot)
# Violin plot with mean and variance of EdU response variable
violinPlot(data2$EdU, col = "skyblue", names = "EdU+ Distribution", ylab = "EdU+")
ggplot(data2, aes(x="", y = EdU)) +
  geom_violin() +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "red") +
  stat_summary(fun.data = "variance", geom = "errorbar", width = 0.2, color = "red")

hist(data2$EdU, col="lightblue", xlab="EdU+ Cell Count", main="Distribution of Response Variable")

# Make violin plot of the response variable by Age
ggplot(data2, aes(x=Age, y=EdU)) + geom_violin() + xlab("Life Stage") + ylab("EdU+ Cell Count") + ggtitle("Distribution of Response Variable by Factor Levels") + theme(plot.title = element_text(hjust = 0.5, size=15, margin=margin(b=10)), axis.title.x = element_text(size=11, margin=margin(t=8)), axis.title.y=element_text(size=11), axis.text.x = element_text(size=10))
# Make violin plot of the response variable by Day
ggplot(data2, aes(x=Day, y=EdU)) + geom_violin(scale="width") + xlab("Day") + ylab("EdU+ Cell Count") + ggtitle("Distribution of Response Variable by Factor Levels") + theme(plot.title = element_text(hjust = 0.5, size=15, margin=margin(b=10)), axis.title.x = element_text(size=12, margin=margin(t=5)), axis.title.y=element_text(size=11), axis.text.x = element_text(size=10)) + scale_x_continuous(breaks = c(1, 4, 10, 15))

edu_summary <- summary(data2$EdU)
mean(data2$EdU)
var(data2$EdU)


# some useful code
# geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE)
# geom_jitter(width=.04, height=0.2)

# Response is log(EdU+)
p1 <-ggplot(subset(data2, Age == "Larvae"), aes(x=Day, y=log(EdU))) + geom_jitter(width=.02, height=0.1, color="red") +       scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Larvae") + geom_smooth(method = "lm", se = FALSE)
p2 <- ggplot(subset(data2, Age == "Juvenile"), aes(x=Day, y=log(EdU))) + geom_jitter(width=.02, height=0.1, color="blue") +       scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Juvenile") + geom_smooth(method = "lm", se = FALSE)
p3 <- ggplot(subset(data2, Age == "Adult"), aes(x=Day, y=log(EdU))) + geom_jitter(width=.02, height=0.1, color="darkgreen") +       scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Adult") + geom_smooth(method = "lm", se = FALSE)

# Response is log(EdU+/Hoechst)
p4 <- ggplot(subset(data2, Age == "Larvae"), aes(x=Day, y=log(EdU/Hoechst))) + geom_point(color="red") +        scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Larvae") + scale_y_continuous(limits = c(-4.7, .05))
p5 <- ggplot(subset(data2, Age == "Juvenile"), aes(x=Day, y=log(EdU/Hoechst))) + geom_point(color="blue") +     scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Juvenile") + scale_y_continuous(limits = c(-4.7, .05))
p6 <- ggplot(subset(data2, Age == "Adult"), aes(x=Day, y=log(EdU/Hoechst))) + geom_point(color="chartreuse3") + scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Adult") + scale_y_continuous(limits = c(-4.7, .05))

# Response is EdU+/Hoechst
p7 <- ggplot(subset(data2, Age == "Larvae"), aes(x=Day, y=EdU/Hoechst)) + geom_point(color="red") + scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Larvae") + geom_smooth(method = "lm", se = FALSE) + scale_y_continuous(limits = c(0, 1.05))
p8 <- ggplot(subset(data2, Age == "Juvenile"), aes(x=Day, y=EdU/Hoechst)) + geom_point(color="blue") + scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Juvenile") + geom_smooth(method = "lm", se = FALSE) + scale_y_continuous(limits = c(0, 1.05))
p9 <- ggplot(subset(data2, Age == "Adult"), aes(x=Day, y=EdU/Hoechst)) + geom_point(color="darkgreen") + scale_x_continuous(breaks = c(1, 4, 10, 15)) + ggtitle("Adult") + geom_smooth(method = "lm", se = FALSE) + scale_y_continuous(limits = c(0, 1.05))

# Arrange the 3 ggplots in one square
grid.arrange(p1, p2, p3, ncol = 3)
grid.arrange(p4, p5, p6, ncol = 3)
grid.arrange(p7, p8, p9, ncol = 3)

subset(data2, EdU > Hoechst)

# Not necessary stuff probably...
par(lty=1)
interaction.plot(data2$Age, data2$Day, data2$EdU, type=c("l","l","l","l"), lty=c(1,1,1,1))
          
                 col=c("red","blue","green","orange"))
interaction.plot(data2$Age, data2$Day, data2$EdU)

# graph dapi against time (do the amount of cells in eye increase?) graph DAPI for a single experimental unit? 
ggplot(subset(data2, Rep == "EYE #1 " & Age == "Larvae" & Section == "Section 5"), aes(x=Day, y=DAPI)) + geom_point()
# group=Section, 
```


``` {r}
library(MASS)
library(car)

# An initial hypothesis is that the iris cells of larvae re-enter around 1 day post injury, juveniles around 4 days, and adults around 10 days.

# Poisson model
glm_poisson <- glm(EdU ~ Day + I(Day^2) + Age + Day*Age + I(Day^2)*Age + offset(log(DAPI)), data=data2)
summary(glm_poisson)
vif(glm_poisson)

# Plot the poisson curves
coefs_pois <- glm_poisson$coefficients
larvae_curve_pois <- function(x) exp(coefs_pois[1] + coefs_pois[2]*x + coefs_pois[3]*x^2)
juvenile_curve_pois <- function(x) exp((coefs_pois[1]+coefs_pois[5]) + (coefs_pois[2]+coefs_pois[7])*x + (coefs_pois[3]+coefs_pois[9])*x^2)
adult_curve_pois<- function(x) exp((coefs_pois[1]+coefs_pois[4]) + (coefs_pois[2]+coefs_pois[6])*x + (coefs_pois[3]+coefs_pois[8])*x^2)
plot(x = c(-2, 30), y = c(-2, 30), type = "n", xlab = "x", ylab = "y")
curve(larvae_curve_pois, col = "red", add = TRUE)
curve(juvenile_curve_pois, col = "blue", add = TRUE)
curve(adult_curve_pois, col = "darkgreen", add = TRUE)

# Negative binomial model
glm_negbinom <- glm.nb(EdU ~ Day + I(Day^2) + Juvenile + Adult + Day*Juvenile + Day*Adult + I(Day^2)*Juvenile + I(Day^2)*Adult + offset(log(DAPI)), data=data2)
summary(glm_negbinom)
vif(glm_negbinom)

# Taking off the insignificant predictors
glm_negbinom_reduced <- glm.nb(EdU ~ Day + I(Day^2) + Juvenile + Adult + I(Day^2)*Juvenile + I(Day^2)*Adult + offset(log(DAPI)), data=data2)
summary(glm_negbinom_reduced)
vif(glm_negbinom)

# Testing significance
anova(glm_negbinom, glm_negbinom_reduced)


# Test something...
lm_negbinom <- lm(log_edu_hoechst ~ Day + I(Day^2) + Age + Day*Age + I(Day^2)*Age, data=data3)
summary(lm_negbinom)
vif(lm_negbinom)

# vifs are above 10 so we need to do remedial measure - center day predictor - doesn't work...
glm_negbinom2 <- glm.nb(EdU ~ day_centered + I(Day^2) + Juvenile + Adult + day_centered*Juvenile + day_centered*Adult + I(day_centered^2)*Juvenile + I(day_centered^2)*Adult + offset(log(DAPI)), data=data2)
summary(glm_negbinom2)
vif(glm_negbinom2)

# Create the negative binomial curve functions
coefs_negbinom <- glm_negbinom$coefficients
larvae_curve_negbinom <- function(x) coefs_negbinom[1] + coefs_negbinom[2]*x + coefs_negbinom[3]*x^2
juvenile_curve_negbinom <- function(x) (coefs_negbinom[1]+coefs_negbinom[5]) + (coefs_negbinom[2]+coefs_negbinom[7])*x + (coefs_negbinom[3]+coefs_negbinom[9])*x^2
adult_curve_negbinom<- function(x) exp((coefs_negbinom[1]+coefs_negbinom[4]) + (coefs_negbinom[2]+coefs_negbinom[6])*x + (coefs_negbinom[3]+coefs_negbinom[8])*x^2) * data2$Hoechst

# find the maximum curve objects
larvae_max <- optimize(larvae_curve_negbinom, interval = c(0, 20), maximum = TRUE)
juvenile_max <- optimize(juvenile_curve_negbinom, interval = c(0, 20), maximum = TRUE)
adult_max <- optimize(adult_curve_negbinom, interval = c(0, 20), maximum = TRUE)

plot(x = c(-2, 20), y = c(-4, 0), type = "n", xlab = "Day", ylab = "log(EdU+/Hoechst)")
title("Response Variable Curves of Fitted Negative Binomial Model")
legend("topright", legend=c("Larvae", "Juvenile", "Adult"), col=c("red", "blue", "chartreuse3"), lwd=2)
curve(larvae_curve_negbinom, col = "red", add = TRUE, lwd=2)
curve(juvenile_curve_negbinom, col = "blue", add = TRUE, lwd=2)
curve(adult_curve_negbinom, col = "chartreuse3", add = TRUE, lwd=2)
points(x=jitter(subset(data3, Juvenile==0 & Adult==0)$Day, amount=0.2), y=subset(data3, Juvenile==0 & Adult==0)$log_edu_hoechst, col="red")
points(x=jitter(subset(data3, Juvenile==1)$Day, amount=0.2), y=subset(data3, Juvenile==1)$log_edu_hoechst, col="blue")
points(x=jitter(subset(data3, Adult==1)$Day, amount=0.2), y=subset(data3, Adult==1)$log_edu_hoechst, col="chartreuse3", lwd=1)
points(x=larvae_max$maximum, y=larvae_max$objective, col="black", pch=19)
points(x=juvenile_max$maximum, y=juvenile_max$objective, col="black", pch=19)
points(x=adult_max$maximum, y=adult_max$objective, col="black", pch=19)
abline(v = larvae_max$maximum, lty = 2)
abline(v = juvenile_max$maximum, lty = 2)
abline(v = adult_max$maximum, lty = 2)

larvae_max$maximum
juvenile_max$maximum
adult_max$maximum





# Some testing bullshit
# Full Model: log(EdU+) = beta0 + beta1(Day) + beta2(Day^2) + beta3(Juvenile) + beta4(Adult) + beta5(Day*Juvenile) + beta6(Day*Adult) + + beta7(Day^2*Juvenile) + beta8(Day^2*Adult)
# Get reduced model for following test. H0: beta5 = beta7 = 0. Test if Juvenile curve is same as adult curve
negbinom_reduced_1 <- glm.nb(EdU ~ Day + I(Day^2) + Juvenile + Adult + Day*Adult + I(Day^2)*Adult + offset(log(DAPI)), data=data2)
summary(negbinom_reduced_1)
vif(negbinom_reduced_1)
# Get reduced model for following test. H0: beta5 = beta7 = 0. Test if Adult curve is same as juvenile curve
negbinom_reduced_2 <- glm.nb(EdU ~ Day + I(Day^2) + Juvenile + Adult + Day*Juvenile + I(Day^2)*Juvenile + offset(log(DAPI)), data=data2)
summary(negbinom_reduced_2)
vif(negbinom_reduced_2)
# Get reduced model for following test. H0: beta5 = beta7 = 0. Test if Adult curve is same as juvenile curve
# change baseline level
data$Age <- relevel(data$Age, ref="Larvae")

anova(negbinom_reduced_1, glm_negbinom)
anova(negbinom_reduced_2, glm_negbinom)


```
``` {r}
library(boot)
library(glmnet)
install.packages("glmnet")


# Model selection
y <- subset(data2, !is.na(EdU))$EdU
x <- model.matrix(~ Day + I(Day^2) + Age + Day*Age + I(Day^2)*Age + offset(log(DAPI)), data = data2)
# specify the glmnet model
glmnet1 <- glmnet(x, y, family = "poisson")

# perform cross-validation to select the best lambda value
cv.fit <- cv.glmnet(x, y, family = "poisson")

# plot the cross-validation error as a function of lambda
plot(cv.fit)

# select the best lambda value based on cross-validation
best.lambda <- cv.fit$lambda.min

# fit the final model using the best lambda value
final.fit <- glmnet(x, y, family = "poisson", lambda = best.lambda)

# get the selected variables and their coefficients
coef(final.fit)

# Best subsets
data_fits <- regsubsets(EdU ~ Day + I(Day^2) + Age + Day*Age + I(Day^2)*Age + offset(log(DAPI)), data=data2, family=poisson)
data_fits_summary = summary(data_fits)

par(mfrow=c(2,2))
# Choose best number of predictor model based on BIC
min_bic = which.min(data_fits_summary$bic)
plot(data_fits_summary$bic, xlab="Number of Variables", ylab="BIC", type="l")
points(min_bic, data_fits_summary$bic[min_bic], col="black", cex=2, pch=20)
# chose the model with min bic
best_bic_model <- coef(data_fits, min_bic)

# Choose best number of predictor model based on AIC/CP
min_cp = which.min(data_fits_summary$cp)
plot(data_fits_summary$cp, xlab="Number of Variables", ylab="CP / AIC", type="l")
points(min_cp, data_fits_summary$cp[min_cp], col="black", cex=2, pch=20)
best_cp_model <- coef(data_fits, min_cp)

# Choose best number of predictor model based on R^2adj
max_R2adj = which.max(data_fits_summary$adjr2)
plot(data_fits_summary$adjr2, xlab="Number of Variables", ylab="R^2 Adjusted", type="l")
points(max_R2adj, data_fits_summary$adjr2[max_R2adj], col="black", cex=2, pch=20)
best_R2adj_model <- coef(data_fits, max_R2adj)

# Display the models best subsets picked for each predictor number
coef(data_fits, 1)
coef(data_fits, 2)
coef(data_fits, 3)
coef(data_fits, 4)
```

Larvae Curve Max: (7.33, 7.125)
Juvenile Curve Max: (11.43, 6.21)
Adult Curve Max: (14.83, 3.52)
